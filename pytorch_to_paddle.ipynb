{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_to_paddle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee58a06cd31446e08d7a67dcc7a9d5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d804bb2a3376430bb2f4e52343261c13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46455ee1ed55498882803b8e0de64b0a",
              "IPY_MODEL_cf47442d30a94ac59ad993577c588546",
              "IPY_MODEL_862d59afdfd742ba8b00100fe1668d16"
            ]
          }
        },
        "d804bb2a3376430bb2f4e52343261c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46455ee1ed55498882803b8e0de64b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46611b347bdb4e4daac0a26723b5fc71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d79393d9cc014a418f35cde294b5e655"
          }
        },
        "cf47442d30a94ac59ad993577c588546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0716109ae3c4446d8e549fdffc6043b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 254695146,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 254695146,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ff14d38ce5b473a9dd60f70b2d73201"
          }
        },
        "862d59afdfd742ba8b00100fe1668d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5fd45fafada843c2a69f357a3e00eb1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 243M/243M [00:02&lt;00:00, 117MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a32fd5cdb46548fd8ab95f1c86c17541"
          }
        },
        "46611b347bdb4e4daac0a26723b5fc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d79393d9cc014a418f35cde294b5e655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0716109ae3c4446d8e549fdffc6043b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ff14d38ce5b473a9dd60f70b2d73201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fd45fafada843c2a69f357a3e00eb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a32fd5cdb46548fd8ab95f1c86c17541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGuYZagp5GkQ"
      },
      "source": [
        "\"\"\"\n",
        "torchvision.models中的wide resnet预训练模型被转化为paddle预训练模型，纯手工完成\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "from paddle import Tensor\n",
        "from paddle.utils.download import get_weights_path_from_url\n",
        "\n",
        "__all__ = []\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': ('https://paddle-hapi.bj.bcebos.com/models/resnet18.pdparams',\n",
        "                 'cf548f46534aa3560945be4b95cd11c4'),\n",
        "    'resnet34': ('https://paddle-hapi.bj.bcebos.com/models/resnet34.pdparams',\n",
        "                 '8d2275cf8706028345f78ac0e1d31969'),\n",
        "    'resnet50': ('https://paddle-hapi.bj.bcebos.com/models/resnet50.pdparams',\n",
        "                 'ca6f485ee1ab0492d38f323885b0ad80'),\n",
        "    'resnet101': ('https://paddle-hapi.bj.bcebos.com/models/resnet101.pdparams',\n",
        "                  '02f35f034ca3858e1e54d4036443c92d'),\n",
        "    'resnet152': ('https://paddle-hapi.bj.bcebos.com/models/resnet152.pdparams',\n",
        "                  '7ad16a2f1e7333859ff986138630fd7a'),\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes: int,\n",
        "        out_planes: int,\n",
        "        stride: int=1,\n",
        "        groups: int=1,\n",
        "        dilation: int=1) -> nn.Conv2D:\n",
        "    \"\"\"3x3 convolution with padding.\"\"\"\n",
        "    return nn.Conv2D(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        dilation=dilation,\n",
        "        bias_attr=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int,\n",
        "        out_planes: int,\n",
        "        stride: int=1) -> nn.Conv2D:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2D(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=1,\n",
        "        stride=stride,\n",
        "        bias_attr=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Layer):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(self,\n",
        "            inplanes: int,\n",
        "            planes: int,\n",
        "            stride: int=1,\n",
        "            downsample: Optional[nn.Layer]=None,\n",
        "            groups: int=1,\n",
        "            base_width: int=64,\n",
        "            dilation: int=1,\n",
        "            norm_layer: Optional[Callable[..., nn.Layer]]=None) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2D\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\n",
        "                'BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\n",
        "                \"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride  # TODO: this line can be deleted\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BottleneckBlock(nn.Layer):\n",
        "    \"\"\"\n",
        "    BottleneckBlock places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "    \"\"\"\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(self,\n",
        "            inplanes: int,\n",
        "            planes: int,\n",
        "            stride: int=1,\n",
        "            downsample: Optional[nn.Layer]=None,\n",
        "            groups: int=1,\n",
        "            base_width: int=64,\n",
        "            dilation: int=1,\n",
        "            norm_layer: Optional[Callable[..., nn.Layer]]=None) -> None:\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2D\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride  # TODO: this line can be deleted\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Layer):\n",
        "    \"\"\"ResNet model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        Block (BasicBlock|BottleneckBlock): block module of model.\n",
        "        depth (int): layers of resnet, default: 50.\n",
        "        num_classes (int): output dim of last fc layer. If num_classes <=0, last fc layer \n",
        "                            will not be defined. Default: 1000.\n",
        "        with_pool (bool): use pool before the last fc layer or not. Default: True.\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import ResNet\n",
        "            from paddle.vision.models.resnet import BottleneckBlock, BasicBlock\n",
        "\n",
        "            resnet50 = ResNet(BottleneckBlock, 50)\n",
        "\n",
        "            resnet18 = ResNet(BasicBlock, 18)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "            block: Type[Union[BasicBlock, BottleneckBlock]],\n",
        "            depth: int,\n",
        "            num_classes: int=1000,\n",
        "            groups: int=1,\n",
        "            width_per_group: int=64,\n",
        "            replace_stride_with_dilation: Optional[List[bool]]=None,\n",
        "            norm_layer: Optional[Callable[..., nn.Layer]]=None,\n",
        "            with_pool: bool=True) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        layer_cfg = {\n",
        "            18: [2, 2, 2, 2],\n",
        "            34: [3, 4, 6, 3],\n",
        "            50: [3, 4, 6, 3],\n",
        "            101: [3, 4, 23, 3],\n",
        "            152: [3, 8, 36, 3]\n",
        "        }\n",
        "        layers = layer_cfg[depth]\n",
        "        self.num_classes = num_classes\n",
        "        self.with_pool = with_pool\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2D\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if not isinstance(replace_stride_with_dilation, (\n",
        "                tuple, list)) or len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                      \"or a 3-element tuple/list, got {}\".format(\n",
        "                           replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2D(\n",
        "            3,\n",
        "            self.inplanes,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias_attr=False)\n",
        "        self.bn1 = self._norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(\n",
        "            block,\n",
        "            128,\n",
        "            layers[1],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(\n",
        "            block,\n",
        "            256,\n",
        "            layers[2],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(\n",
        "            block,\n",
        "            512,\n",
        "            layers[3],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[2])\n",
        "        if with_pool:\n",
        "            self.avgpool = nn.AdaptiveAvgPool2D((1, 1))\n",
        "        if num_classes > 0:\n",
        "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self,\n",
        "            block: Type[Union[BasicBlock, BottleneckBlock]],\n",
        "            planes: int,\n",
        "            blocks: int,\n",
        "            stride: int=1,\n",
        "            dilate: bool=False) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                 norm_layer(planes * block.expansion),)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.with_pool:\n",
        "            x = self.avgpool(x)\n",
        "\n",
        "        if self.num_classes > 0:\n",
        "            x = paddle.flatten(x, 1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def _resnet(arch: str,\n",
        "        block: Type[Union[BasicBlock, BottleneckBlock]],\n",
        "        depth: int,\n",
        "        pretrained: bool,\n",
        "        **kwargs: Any) -> ResNet:\n",
        "    model = ResNet(block, depth, **kwargs)\n",
        "    if pretrained:\n",
        "        assert arch in model_urls, \"{} model do not have a pretrained model now, you should set pretrained=False\".format(\n",
        "            arch)\n",
        "        weights_path = get_weights_path_from_url(model_urls[arch][0],\n",
        "                               model_urls[arch][1])\n",
        "        param = paddle.load(weights_path)\n",
        "        model.set_dict(param)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "        Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import resnet18\n",
        "\n",
        "            # build model\n",
        "            model = resnet18()\n",
        "\n",
        "            # build model and load imagenet pretrained weight\n",
        "            # model = resnet18(pretrained=True)\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, 18, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def resnet34(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "    \n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import resnet34\n",
        "\n",
        "            # build model\n",
        "            model = resnet34()\n",
        "\n",
        "            # build model and load imagenet pretrained weight\n",
        "            # model = resnet34(pretrained=True)\n",
        "    \"\"\"\n",
        "    return _resnet('resnet34', BasicBlock, 34, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def resnet50(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import resnet50\n",
        "\n",
        "            # build model\n",
        "            model = resnet50()\n",
        "\n",
        "            # build model and load imagenet pretrained weight\n",
        "            # model = resnet50(pretrained=True)\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', BottleneckBlock, 50, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def resnet101(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-101 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import resnet101\n",
        "\n",
        "            # build model\n",
        "            model = resnet101()\n",
        "\n",
        "            # build model and load imagenet pretrained weight\n",
        "            model = resnet101(pretrained=True)\n",
        "    \"\"\"\n",
        "    return _resnet('resnet101', BottleneckBlock, 101, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def resnet152(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"ResNet-152 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import resnet152\n",
        "\n",
        "            # build model\n",
        "            model = resnet152()\n",
        "\n",
        "            # build model and load imagenet pretrained weight\n",
        "            model = resnet152(pretrained=True)\n",
        "    \"\"\"\n",
        "    return _resnet('resnet152', BottleneckBlock, 152, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def wide_resnet50_2(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"Wide ResNet-50-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n",
        "\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import wide_resnet50_2\n",
        "\n",
        "            # build model\n",
        "            model = wide_resnet50_2()\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet50_2', BottleneckBlock, 50, pretrained, **kwargs)\n",
        "\n",
        "\n",
        "def wide_resnet101_2(pretrained: bool=False, **kwargs: Any) -> ResNet:\n",
        "    r\"\"\"Wide ResNet-101-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n",
        "\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "\n",
        "    Examples:\n",
        "        .. code-block:: python\n",
        "\n",
        "            from paddle.vision.models import wide_resnet101_2\n",
        "\n",
        "            # build model\n",
        "            model = wide_resnet101_2()\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet101_2', BottleneckBlock, 101, pretrained, **kwargs)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-S608QZ7q0A"
      },
      "source": [
        "# compare the parameters by hand\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import paddle\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ee58a06cd31446e08d7a67dcc7a9d5e5",
            "d804bb2a3376430bb2f4e52343261c13",
            "46455ee1ed55498882803b8e0de64b0a",
            "cf47442d30a94ac59ad993577c588546",
            "862d59afdfd742ba8b00100fe1668d16",
            "46611b347bdb4e4daac0a26723b5fc71",
            "d79393d9cc014a418f35cde294b5e655",
            "0716109ae3c4446d8e549fdffc6043b8",
            "3ff14d38ce5b473a9dd60f70b2d73201",
            "5fd45fafada843c2a69f357a3e00eb1a",
            "a32fd5cdb46548fd8ab95f1c86c17541"
          ]
        },
        "id": "0BS9q7blMGlw",
        "outputId": "936cb92e-4e24-4f95-9081-223bf8651a26"
      },
      "source": [
        "torch_model = torchvision.models.wide_resnet101_2(pretrained=True)\n",
        "paddle_model = wide_resnet101_2(pretrained=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet101_2-32ee1156.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee58a06cd31446e08d7a67dcc7a9d5e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/243M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6nJLMczOFKG",
        "outputId": "e8a5fd5d-5194-408d-a933-7769b22a22a9"
      },
      "source": [
        "print(torch_model.state_dict().keys())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer3.6.conv1.weight', 'layer3.6.bn1.weight', 'layer3.6.bn1.bias', 'layer3.6.bn1.running_mean', 'layer3.6.bn1.running_var', 'layer3.6.bn1.num_batches_tracked', 'layer3.6.conv2.weight', 'layer3.6.bn2.weight', 'layer3.6.bn2.bias', 'layer3.6.bn2.running_mean', 'layer3.6.bn2.running_var', 'layer3.6.bn2.num_batches_tracked', 'layer3.6.conv3.weight', 'layer3.6.bn3.weight', 'layer3.6.bn3.bias', 'layer3.6.bn3.running_mean', 'layer3.6.bn3.running_var', 'layer3.6.bn3.num_batches_tracked', 'layer3.7.conv1.weight', 'layer3.7.bn1.weight', 'layer3.7.bn1.bias', 'layer3.7.bn1.running_mean', 'layer3.7.bn1.running_var', 'layer3.7.bn1.num_batches_tracked', 'layer3.7.conv2.weight', 'layer3.7.bn2.weight', 'layer3.7.bn2.bias', 'layer3.7.bn2.running_mean', 'layer3.7.bn2.running_var', 'layer3.7.bn2.num_batches_tracked', 'layer3.7.conv3.weight', 'layer3.7.bn3.weight', 'layer3.7.bn3.bias', 'layer3.7.bn3.running_mean', 'layer3.7.bn3.running_var', 'layer3.7.bn3.num_batches_tracked', 'layer3.8.conv1.weight', 'layer3.8.bn1.weight', 'layer3.8.bn1.bias', 'layer3.8.bn1.running_mean', 'layer3.8.bn1.running_var', 'layer3.8.bn1.num_batches_tracked', 'layer3.8.conv2.weight', 'layer3.8.bn2.weight', 'layer3.8.bn2.bias', 'layer3.8.bn2.running_mean', 'layer3.8.bn2.running_var', 'layer3.8.bn2.num_batches_tracked', 'layer3.8.conv3.weight', 'layer3.8.bn3.weight', 'layer3.8.bn3.bias', 'layer3.8.bn3.running_mean', 'layer3.8.bn3.running_var', 'layer3.8.bn3.num_batches_tracked', 'layer3.9.conv1.weight', 'layer3.9.bn1.weight', 'layer3.9.bn1.bias', 'layer3.9.bn1.running_mean', 'layer3.9.bn1.running_var', 'layer3.9.bn1.num_batches_tracked', 'layer3.9.conv2.weight', 'layer3.9.bn2.weight', 'layer3.9.bn2.bias', 'layer3.9.bn2.running_mean', 'layer3.9.bn2.running_var', 'layer3.9.bn2.num_batches_tracked', 'layer3.9.conv3.weight', 'layer3.9.bn3.weight', 'layer3.9.bn3.bias', 'layer3.9.bn3.running_mean', 'layer3.9.bn3.running_var', 'layer3.9.bn3.num_batches_tracked', 'layer3.10.conv1.weight', 'layer3.10.bn1.weight', 'layer3.10.bn1.bias', 'layer3.10.bn1.running_mean', 'layer3.10.bn1.running_var', 'layer3.10.bn1.num_batches_tracked', 'layer3.10.conv2.weight', 'layer3.10.bn2.weight', 'layer3.10.bn2.bias', 'layer3.10.bn2.running_mean', 'layer3.10.bn2.running_var', 'layer3.10.bn2.num_batches_tracked', 'layer3.10.conv3.weight', 'layer3.10.bn3.weight', 'layer3.10.bn3.bias', 'layer3.10.bn3.running_mean', 'layer3.10.bn3.running_var', 'layer3.10.bn3.num_batches_tracked', 'layer3.11.conv1.weight', 'layer3.11.bn1.weight', 'layer3.11.bn1.bias', 'layer3.11.bn1.running_mean', 'layer3.11.bn1.running_var', 'layer3.11.bn1.num_batches_tracked', 'layer3.11.conv2.weight', 'layer3.11.bn2.weight', 'layer3.11.bn2.bias', 'layer3.11.bn2.running_mean', 'layer3.11.bn2.running_var', 'layer3.11.bn2.num_batches_tracked', 'layer3.11.conv3.weight', 'layer3.11.bn3.weight', 'layer3.11.bn3.bias', 'layer3.11.bn3.running_mean', 'layer3.11.bn3.running_var', 'layer3.11.bn3.num_batches_tracked', 'layer3.12.conv1.weight', 'layer3.12.bn1.weight', 'layer3.12.bn1.bias', 'layer3.12.bn1.running_mean', 'layer3.12.bn1.running_var', 'layer3.12.bn1.num_batches_tracked', 'layer3.12.conv2.weight', 'layer3.12.bn2.weight', 'layer3.12.bn2.bias', 'layer3.12.bn2.running_mean', 'layer3.12.bn2.running_var', 'layer3.12.bn2.num_batches_tracked', 'layer3.12.conv3.weight', 'layer3.12.bn3.weight', 'layer3.12.bn3.bias', 'layer3.12.bn3.running_mean', 'layer3.12.bn3.running_var', 'layer3.12.bn3.num_batches_tracked', 'layer3.13.conv1.weight', 'layer3.13.bn1.weight', 'layer3.13.bn1.bias', 'layer3.13.bn1.running_mean', 'layer3.13.bn1.running_var', 'layer3.13.bn1.num_batches_tracked', 'layer3.13.conv2.weight', 'layer3.13.bn2.weight', 'layer3.13.bn2.bias', 'layer3.13.bn2.running_mean', 'layer3.13.bn2.running_var', 'layer3.13.bn2.num_batches_tracked', 'layer3.13.conv3.weight', 'layer3.13.bn3.weight', 'layer3.13.bn3.bias', 'layer3.13.bn3.running_mean', 'layer3.13.bn3.running_var', 'layer3.13.bn3.num_batches_tracked', 'layer3.14.conv1.weight', 'layer3.14.bn1.weight', 'layer3.14.bn1.bias', 'layer3.14.bn1.running_mean', 'layer3.14.bn1.running_var', 'layer3.14.bn1.num_batches_tracked', 'layer3.14.conv2.weight', 'layer3.14.bn2.weight', 'layer3.14.bn2.bias', 'layer3.14.bn2.running_mean', 'layer3.14.bn2.running_var', 'layer3.14.bn2.num_batches_tracked', 'layer3.14.conv3.weight', 'layer3.14.bn3.weight', 'layer3.14.bn3.bias', 'layer3.14.bn3.running_mean', 'layer3.14.bn3.running_var', 'layer3.14.bn3.num_batches_tracked', 'layer3.15.conv1.weight', 'layer3.15.bn1.weight', 'layer3.15.bn1.bias', 'layer3.15.bn1.running_mean', 'layer3.15.bn1.running_var', 'layer3.15.bn1.num_batches_tracked', 'layer3.15.conv2.weight', 'layer3.15.bn2.weight', 'layer3.15.bn2.bias', 'layer3.15.bn2.running_mean', 'layer3.15.bn2.running_var', 'layer3.15.bn2.num_batches_tracked', 'layer3.15.conv3.weight', 'layer3.15.bn3.weight', 'layer3.15.bn3.bias', 'layer3.15.bn3.running_mean', 'layer3.15.bn3.running_var', 'layer3.15.bn3.num_batches_tracked', 'layer3.16.conv1.weight', 'layer3.16.bn1.weight', 'layer3.16.bn1.bias', 'layer3.16.bn1.running_mean', 'layer3.16.bn1.running_var', 'layer3.16.bn1.num_batches_tracked', 'layer3.16.conv2.weight', 'layer3.16.bn2.weight', 'layer3.16.bn2.bias', 'layer3.16.bn2.running_mean', 'layer3.16.bn2.running_var', 'layer3.16.bn2.num_batches_tracked', 'layer3.16.conv3.weight', 'layer3.16.bn3.weight', 'layer3.16.bn3.bias', 'layer3.16.bn3.running_mean', 'layer3.16.bn3.running_var', 'layer3.16.bn3.num_batches_tracked', 'layer3.17.conv1.weight', 'layer3.17.bn1.weight', 'layer3.17.bn1.bias', 'layer3.17.bn1.running_mean', 'layer3.17.bn1.running_var', 'layer3.17.bn1.num_batches_tracked', 'layer3.17.conv2.weight', 'layer3.17.bn2.weight', 'layer3.17.bn2.bias', 'layer3.17.bn2.running_mean', 'layer3.17.bn2.running_var', 'layer3.17.bn2.num_batches_tracked', 'layer3.17.conv3.weight', 'layer3.17.bn3.weight', 'layer3.17.bn3.bias', 'layer3.17.bn3.running_mean', 'layer3.17.bn3.running_var', 'layer3.17.bn3.num_batches_tracked', 'layer3.18.conv1.weight', 'layer3.18.bn1.weight', 'layer3.18.bn1.bias', 'layer3.18.bn1.running_mean', 'layer3.18.bn1.running_var', 'layer3.18.bn1.num_batches_tracked', 'layer3.18.conv2.weight', 'layer3.18.bn2.weight', 'layer3.18.bn2.bias', 'layer3.18.bn2.running_mean', 'layer3.18.bn2.running_var', 'layer3.18.bn2.num_batches_tracked', 'layer3.18.conv3.weight', 'layer3.18.bn3.weight', 'layer3.18.bn3.bias', 'layer3.18.bn3.running_mean', 'layer3.18.bn3.running_var', 'layer3.18.bn3.num_batches_tracked', 'layer3.19.conv1.weight', 'layer3.19.bn1.weight', 'layer3.19.bn1.bias', 'layer3.19.bn1.running_mean', 'layer3.19.bn1.running_var', 'layer3.19.bn1.num_batches_tracked', 'layer3.19.conv2.weight', 'layer3.19.bn2.weight', 'layer3.19.bn2.bias', 'layer3.19.bn2.running_mean', 'layer3.19.bn2.running_var', 'layer3.19.bn2.num_batches_tracked', 'layer3.19.conv3.weight', 'layer3.19.bn3.weight', 'layer3.19.bn3.bias', 'layer3.19.bn3.running_mean', 'layer3.19.bn3.running_var', 'layer3.19.bn3.num_batches_tracked', 'layer3.20.conv1.weight', 'layer3.20.bn1.weight', 'layer3.20.bn1.bias', 'layer3.20.bn1.running_mean', 'layer3.20.bn1.running_var', 'layer3.20.bn1.num_batches_tracked', 'layer3.20.conv2.weight', 'layer3.20.bn2.weight', 'layer3.20.bn2.bias', 'layer3.20.bn2.running_mean', 'layer3.20.bn2.running_var', 'layer3.20.bn2.num_batches_tracked', 'layer3.20.conv3.weight', 'layer3.20.bn3.weight', 'layer3.20.bn3.bias', 'layer3.20.bn3.running_mean', 'layer3.20.bn3.running_var', 'layer3.20.bn3.num_batches_tracked', 'layer3.21.conv1.weight', 'layer3.21.bn1.weight', 'layer3.21.bn1.bias', 'layer3.21.bn1.running_mean', 'layer3.21.bn1.running_var', 'layer3.21.bn1.num_batches_tracked', 'layer3.21.conv2.weight', 'layer3.21.bn2.weight', 'layer3.21.bn2.bias', 'layer3.21.bn2.running_mean', 'layer3.21.bn2.running_var', 'layer3.21.bn2.num_batches_tracked', 'layer3.21.conv3.weight', 'layer3.21.bn3.weight', 'layer3.21.bn3.bias', 'layer3.21.bn3.running_mean', 'layer3.21.bn3.running_var', 'layer3.21.bn3.num_batches_tracked', 'layer3.22.conv1.weight', 'layer3.22.bn1.weight', 'layer3.22.bn1.bias', 'layer3.22.bn1.running_mean', 'layer3.22.bn1.running_var', 'layer3.22.bn1.num_batches_tracked', 'layer3.22.conv2.weight', 'layer3.22.bn2.weight', 'layer3.22.bn2.bias', 'layer3.22.bn2.running_mean', 'layer3.22.bn2.running_var', 'layer3.22.bn2.num_batches_tracked', 'layer3.22.conv3.weight', 'layer3.22.bn3.weight', 'layer3.22.bn3.bias', 'layer3.22.bn3.running_mean', 'layer3.22.bn3.running_var', 'layer3.22.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkA5afiTh02k",
        "outputId": "c165193d-5d81-4864-9342-335518286f02"
      },
      "source": [
        "print(paddle_model.state_dict().keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1._mean', 'bn1._variance', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1._mean', 'layer1.0.bn1._variance', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2._mean', 'layer1.0.bn2._variance', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3._mean', 'layer1.0.bn3._variance', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1._mean', 'layer1.0.downsample.1._variance', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1._mean', 'layer1.1.bn1._variance', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2._mean', 'layer1.1.bn2._variance', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3._mean', 'layer1.1.bn3._variance', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1._mean', 'layer1.2.bn1._variance', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2._mean', 'layer1.2.bn2._variance', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3._mean', 'layer1.2.bn3._variance', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1._mean', 'layer2.0.bn1._variance', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2._mean', 'layer2.0.bn2._variance', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3._mean', 'layer2.0.bn3._variance', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1._mean', 'layer2.0.downsample.1._variance', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1._mean', 'layer2.1.bn1._variance', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2._mean', 'layer2.1.bn2._variance', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3._mean', 'layer2.1.bn3._variance', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1._mean', 'layer2.2.bn1._variance', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2._mean', 'layer2.2.bn2._variance', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3._mean', 'layer2.2.bn3._variance', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1._mean', 'layer2.3.bn1._variance', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2._mean', 'layer2.3.bn2._variance', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3._mean', 'layer2.3.bn3._variance', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1._mean', 'layer3.0.bn1._variance', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2._mean', 'layer3.0.bn2._variance', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3._mean', 'layer3.0.bn3._variance', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1._mean', 'layer3.0.downsample.1._variance', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1._mean', 'layer3.1.bn1._variance', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2._mean', 'layer3.1.bn2._variance', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3._mean', 'layer3.1.bn3._variance', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1._mean', 'layer3.2.bn1._variance', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2._mean', 'layer3.2.bn2._variance', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3._mean', 'layer3.2.bn3._variance', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1._mean', 'layer3.3.bn1._variance', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2._mean', 'layer3.3.bn2._variance', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3._mean', 'layer3.3.bn3._variance', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1._mean', 'layer3.4.bn1._variance', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2._mean', 'layer3.4.bn2._variance', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3._mean', 'layer3.4.bn3._variance', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1._mean', 'layer3.5.bn1._variance', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2._mean', 'layer3.5.bn2._variance', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3._mean', 'layer3.5.bn3._variance', 'layer3.6.conv1.weight', 'layer3.6.bn1.weight', 'layer3.6.bn1.bias', 'layer3.6.bn1._mean', 'layer3.6.bn1._variance', 'layer3.6.conv2.weight', 'layer3.6.bn2.weight', 'layer3.6.bn2.bias', 'layer3.6.bn2._mean', 'layer3.6.bn2._variance', 'layer3.6.conv3.weight', 'layer3.6.bn3.weight', 'layer3.6.bn3.bias', 'layer3.6.bn3._mean', 'layer3.6.bn3._variance', 'layer3.7.conv1.weight', 'layer3.7.bn1.weight', 'layer3.7.bn1.bias', 'layer3.7.bn1._mean', 'layer3.7.bn1._variance', 'layer3.7.conv2.weight', 'layer3.7.bn2.weight', 'layer3.7.bn2.bias', 'layer3.7.bn2._mean', 'layer3.7.bn2._variance', 'layer3.7.conv3.weight', 'layer3.7.bn3.weight', 'layer3.7.bn3.bias', 'layer3.7.bn3._mean', 'layer3.7.bn3._variance', 'layer3.8.conv1.weight', 'layer3.8.bn1.weight', 'layer3.8.bn1.bias', 'layer3.8.bn1._mean', 'layer3.8.bn1._variance', 'layer3.8.conv2.weight', 'layer3.8.bn2.weight', 'layer3.8.bn2.bias', 'layer3.8.bn2._mean', 'layer3.8.bn2._variance', 'layer3.8.conv3.weight', 'layer3.8.bn3.weight', 'layer3.8.bn3.bias', 'layer3.8.bn3._mean', 'layer3.8.bn3._variance', 'layer3.9.conv1.weight', 'layer3.9.bn1.weight', 'layer3.9.bn1.bias', 'layer3.9.bn1._mean', 'layer3.9.bn1._variance', 'layer3.9.conv2.weight', 'layer3.9.bn2.weight', 'layer3.9.bn2.bias', 'layer3.9.bn2._mean', 'layer3.9.bn2._variance', 'layer3.9.conv3.weight', 'layer3.9.bn3.weight', 'layer3.9.bn3.bias', 'layer3.9.bn3._mean', 'layer3.9.bn3._variance', 'layer3.10.conv1.weight', 'layer3.10.bn1.weight', 'layer3.10.bn1.bias', 'layer3.10.bn1._mean', 'layer3.10.bn1._variance', 'layer3.10.conv2.weight', 'layer3.10.bn2.weight', 'layer3.10.bn2.bias', 'layer3.10.bn2._mean', 'layer3.10.bn2._variance', 'layer3.10.conv3.weight', 'layer3.10.bn3.weight', 'layer3.10.bn3.bias', 'layer3.10.bn3._mean', 'layer3.10.bn3._variance', 'layer3.11.conv1.weight', 'layer3.11.bn1.weight', 'layer3.11.bn1.bias', 'layer3.11.bn1._mean', 'layer3.11.bn1._variance', 'layer3.11.conv2.weight', 'layer3.11.bn2.weight', 'layer3.11.bn2.bias', 'layer3.11.bn2._mean', 'layer3.11.bn2._variance', 'layer3.11.conv3.weight', 'layer3.11.bn3.weight', 'layer3.11.bn3.bias', 'layer3.11.bn3._mean', 'layer3.11.bn3._variance', 'layer3.12.conv1.weight', 'layer3.12.bn1.weight', 'layer3.12.bn1.bias', 'layer3.12.bn1._mean', 'layer3.12.bn1._variance', 'layer3.12.conv2.weight', 'layer3.12.bn2.weight', 'layer3.12.bn2.bias', 'layer3.12.bn2._mean', 'layer3.12.bn2._variance', 'layer3.12.conv3.weight', 'layer3.12.bn3.weight', 'layer3.12.bn3.bias', 'layer3.12.bn3._mean', 'layer3.12.bn3._variance', 'layer3.13.conv1.weight', 'layer3.13.bn1.weight', 'layer3.13.bn1.bias', 'layer3.13.bn1._mean', 'layer3.13.bn1._variance', 'layer3.13.conv2.weight', 'layer3.13.bn2.weight', 'layer3.13.bn2.bias', 'layer3.13.bn2._mean', 'layer3.13.bn2._variance', 'layer3.13.conv3.weight', 'layer3.13.bn3.weight', 'layer3.13.bn3.bias', 'layer3.13.bn3._mean', 'layer3.13.bn3._variance', 'layer3.14.conv1.weight', 'layer3.14.bn1.weight', 'layer3.14.bn1.bias', 'layer3.14.bn1._mean', 'layer3.14.bn1._variance', 'layer3.14.conv2.weight', 'layer3.14.bn2.weight', 'layer3.14.bn2.bias', 'layer3.14.bn2._mean', 'layer3.14.bn2._variance', 'layer3.14.conv3.weight', 'layer3.14.bn3.weight', 'layer3.14.bn3.bias', 'layer3.14.bn3._mean', 'layer3.14.bn3._variance', 'layer3.15.conv1.weight', 'layer3.15.bn1.weight', 'layer3.15.bn1.bias', 'layer3.15.bn1._mean', 'layer3.15.bn1._variance', 'layer3.15.conv2.weight', 'layer3.15.bn2.weight', 'layer3.15.bn2.bias', 'layer3.15.bn2._mean', 'layer3.15.bn2._variance', 'layer3.15.conv3.weight', 'layer3.15.bn3.weight', 'layer3.15.bn3.bias', 'layer3.15.bn3._mean', 'layer3.15.bn3._variance', 'layer3.16.conv1.weight', 'layer3.16.bn1.weight', 'layer3.16.bn1.bias', 'layer3.16.bn1._mean', 'layer3.16.bn1._variance', 'layer3.16.conv2.weight', 'layer3.16.bn2.weight', 'layer3.16.bn2.bias', 'layer3.16.bn2._mean', 'layer3.16.bn2._variance', 'layer3.16.conv3.weight', 'layer3.16.bn3.weight', 'layer3.16.bn3.bias', 'layer3.16.bn3._mean', 'layer3.16.bn3._variance', 'layer3.17.conv1.weight', 'layer3.17.bn1.weight', 'layer3.17.bn1.bias', 'layer3.17.bn1._mean', 'layer3.17.bn1._variance', 'layer3.17.conv2.weight', 'layer3.17.bn2.weight', 'layer3.17.bn2.bias', 'layer3.17.bn2._mean', 'layer3.17.bn2._variance', 'layer3.17.conv3.weight', 'layer3.17.bn3.weight', 'layer3.17.bn3.bias', 'layer3.17.bn3._mean', 'layer3.17.bn3._variance', 'layer3.18.conv1.weight', 'layer3.18.bn1.weight', 'layer3.18.bn1.bias', 'layer3.18.bn1._mean', 'layer3.18.bn1._variance', 'layer3.18.conv2.weight', 'layer3.18.bn2.weight', 'layer3.18.bn2.bias', 'layer3.18.bn2._mean', 'layer3.18.bn2._variance', 'layer3.18.conv3.weight', 'layer3.18.bn3.weight', 'layer3.18.bn3.bias', 'layer3.18.bn3._mean', 'layer3.18.bn3._variance', 'layer3.19.conv1.weight', 'layer3.19.bn1.weight', 'layer3.19.bn1.bias', 'layer3.19.bn1._mean', 'layer3.19.bn1._variance', 'layer3.19.conv2.weight', 'layer3.19.bn2.weight', 'layer3.19.bn2.bias', 'layer3.19.bn2._mean', 'layer3.19.bn2._variance', 'layer3.19.conv3.weight', 'layer3.19.bn3.weight', 'layer3.19.bn3.bias', 'layer3.19.bn3._mean', 'layer3.19.bn3._variance', 'layer3.20.conv1.weight', 'layer3.20.bn1.weight', 'layer3.20.bn1.bias', 'layer3.20.bn1._mean', 'layer3.20.bn1._variance', 'layer3.20.conv2.weight', 'layer3.20.bn2.weight', 'layer3.20.bn2.bias', 'layer3.20.bn2._mean', 'layer3.20.bn2._variance', 'layer3.20.conv3.weight', 'layer3.20.bn3.weight', 'layer3.20.bn3.bias', 'layer3.20.bn3._mean', 'layer3.20.bn3._variance', 'layer3.21.conv1.weight', 'layer3.21.bn1.weight', 'layer3.21.bn1.bias', 'layer3.21.bn1._mean', 'layer3.21.bn1._variance', 'layer3.21.conv2.weight', 'layer3.21.bn2.weight', 'layer3.21.bn2.bias', 'layer3.21.bn2._mean', 'layer3.21.bn2._variance', 'layer3.21.conv3.weight', 'layer3.21.bn3.weight', 'layer3.21.bn3.bias', 'layer3.21.bn3._mean', 'layer3.21.bn3._variance', 'layer3.22.conv1.weight', 'layer3.22.bn1.weight', 'layer3.22.bn1.bias', 'layer3.22.bn1._mean', 'layer3.22.bn1._variance', 'layer3.22.conv2.weight', 'layer3.22.bn2.weight', 'layer3.22.bn2.bias', 'layer3.22.bn2._mean', 'layer3.22.bn2._variance', 'layer3.22.conv3.weight', 'layer3.22.bn3.weight', 'layer3.22.bn3.bias', 'layer3.22.bn3._mean', 'layer3.22.bn3._variance', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1._mean', 'layer4.0.bn1._variance', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2._mean', 'layer4.0.bn2._variance', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3._mean', 'layer4.0.bn3._variance', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1._mean', 'layer4.0.downsample.1._variance', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1._mean', 'layer4.1.bn1._variance', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2._mean', 'layer4.1.bn2._variance', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3._mean', 'layer4.1.bn3._variance', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1._mean', 'layer4.2.bn1._variance', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2._mean', 'layer4.2.bn2._variance', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3._mean', 'layer4.2.bn3._variance', 'fc.weight', 'fc.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJjFOUlvnsu"
      },
      "source": [
        "from collections import OrderedDict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4yf9J7yj7NE"
      },
      "source": [
        "paddle_state_dict = OrderedDict()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGJAicSKs0As"
      },
      "source": [
        "for torch_key in torch_model.state_dict().keys():\n",
        "  if torch_key in paddle_model.state_dict():\n",
        "    paddle_state_dict[torch_key] = torch_model.state_dict()[torch_key].numpy()\n",
        "  elif \"running_mean\" in torch_key:\n",
        "    new_key = torch_key.replace(\"running_mean\", \"_mean\")\n",
        "    assert new_key in paddle_model.state_dict(), \"Error, torch model has key {}\".format(torch_key)\n",
        "    paddle_state_dict[new_key] = torch_model.state_dict()[torch_key].numpy() \n",
        "  elif \"running_var\" in torch_key:\n",
        "    new_key = torch_key.replace(\"running_var\", \"_variance\")\n",
        "    assert new_key in paddle_model.state_dict(), \"Error, torch model has key {}\".format(torch_key)\n",
        "    paddle_state_dict[new_key] = torch_model.state_dict()[torch_key].numpy()   \n",
        "  elif \"num_batches_tracked\" in torch_key:\n",
        "    continue\n",
        "  else:\n",
        "    assert False, \"Error, torch model has key {}\".format(torch_key)\n",
        "\n",
        "paddle_state_dict['fc.weight'] = np.transpose(paddle_state_dict['fc.weight'], (1, 0))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IcZ1tl_vi-U",
        "outputId": "7ad9a57b-ad61-45f6-bc15-d57c61dca569"
      },
      "source": [
        "paddle_state_dict.keys() == paddle_model.state_dict().keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXi_1vKIwCIO"
      },
      "source": [
        "paddle_model.set_state_dict(paddle_state_dict)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFMDp9aRxSWx"
      },
      "source": [
        "paddle.save(paddle_model.state_dict(), \"wide_resnet101_2.pdparams\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PZZ1c8-079p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
